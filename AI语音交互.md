# GuidingDogä¸­å…³äºAIè¯­éŸ³äº¤äº’æ¨¡å—Â·

## å®ç°ç›®çš„

è¿™æ˜¯ä¸€ä¸ªåŸºäº ROS çš„æ™ºèƒ½è¯­éŸ³äº¤äº’ç³»ç»Ÿï¼Œä¸»è¦å®ç°äº†**è¯­éŸ³è¯†åˆ« + AIå¯¹è¯ + è¯­éŸ³åˆæˆ + æœºå™¨äººæ§åˆ¶**çš„å®Œæ•´åŠŸèƒ½é“¾è·¯ã€‚

## ROSåŒ…æ¡†æ¶

src/AI/
â”œâ”€â”€ ğŸ“„ CMakeLists.txt          # ROSåŒ…æ„å»ºé…ç½®
â”œâ”€â”€ ğŸ“„ package.xml             # ROSåŒ…ä¾èµ–å£°æ˜
â””â”€â”€ scripts/                   # Pythonè„šæœ¬ç›®å½•
    â”œâ”€â”€ ğŸ“„ hello.py            # ç®€å•æµ‹è¯•è„šæœ¬
    â”œâ”€â”€ ğŸ“„ node.py             # ROSè¯é¢˜å‘å¸ƒè€…ç¤ºä¾‹
    â”œâ”€â”€ ğŸ“„ node2.py            # ROSè¯é¢˜è®¢é˜…è€…ç¤ºä¾‹
    â”œâ”€â”€ ğŸ“„ testMyPackage.py    # ä¸»ç¨‹åºå…¥å£ï¼ˆæ ¸å¿ƒåº”ç”¨ï¼‰
    â””â”€â”€ FsrAiAgent/            # æ ¸å¿ƒAIä»£ç†æ¨¡å—
        â”œâ”€â”€ ğŸ“„ init.py     # æ¨¡å—å¯¼å…¥é…ç½®
        â”œâ”€â”€ ğŸ¤ ASR_Paraformer.py      # è¯­éŸ³è¯†åˆ«æ¨¡å—
        â”œâ”€â”€ ğŸ¤– QwenLangchain.py       # AIå¯¹è¯ä»£ç†æ¨¡å—
        â”œâ”€â”€ ğŸ”Š TTS_Sambert.py         # è¯­éŸ³åˆæˆæ¨¡å—
        â””â”€â”€ ğŸ› ï¸ MyTools.py              # å·¥å…·å‡½æ•°é›†åˆ

## ä»£ç è§£é‡Š

### src/AI/scripts

#### node.py

**è¯¥è„šæœ¬å®ç°äº†ä¸€ä¸ªæ¶ˆæ¯å‘å¸ƒæ–¹ï¼ŒæŒç»­å‘ROSè¯é¢˜å‘å¸ƒå¸¦æœ‰é€’å¢ç¼–å·çš„æ–‡æœ¬æ¶ˆæ¯**

åˆå§‹åŒ–èŠ‚ç‚¹

```py
rospy.init_node("talker_p")
```

åˆ›å»ºå‘å¸ƒè€…å¯¹è±¡

```py
pub = rospy.Publisher("chatter",String,queue_size=10)  #è¯é¢˜åè¯ï¼šchatter    ç¼“å­˜æ¡æ•°ï¼š10
```

æ¶ˆæ¯å‘å¸ƒå¾ªç¯

```py
msg = String()  #åˆ›å»º msg å¯¹è±¡
msg_front = "hello ä½ å¥½"
count = 0   #è®¡æ•°å™¨ 
rate = rospy.Rate(1)  #è®¾ç½®å¾ªç¯é¢‘ç‡
while not rospy.is_shutdown():
    msg.data = msg_front + str(count)  #æ‹¼æ¥å­—ç¬¦ä¸²
    pub.publish(msg)
    rate.sleep()
    rospy.loginfo("å†™å‡ºçš„æ•°æ®:%s",msg.data)
    count += 1  #è®¡æ•°å™¨+1
```

#### node2.py

**è¯¥è„šæœ¬å®ç°äº†ä¸€ä¸ªæ¶ˆæ¯è®¢é˜…æ–¹ï¼Œç›‘å¬æŒ‡å®šROSè¯é¢˜å¹¶å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯**

å›è°ƒå‡½æ•°å®šä¹‰ï¼Œå½“æ¥æ”¶åˆ°æ¶ˆæ¯æ—¶è‡ªåŠ¨è°ƒç”¨ï¼Œæ‰“å°æ¥æ”¶åˆ°çš„æ¶ˆæ¯å†…å®¹

```py
def doMsg(msg):
    rospy.loginfo("I heard:%s",msg.data)
```

ROSèŠ‚ç‚¹åˆå§‹åŒ–

```py
rospy.init_node("listener_p")
```

åˆ›å»ºè®¢é˜…å¯¹è±¡å¹¶ä¸”ä¿æŒèŠ‚ç‚¹è¿è¡Œ

```py
sub = rospy.Subscriber("chatter",String,doMsg,queue_size=10)  #å¤„ç†è®¢é˜…çš„æ¶ˆæ¯(å›è°ƒå‡½æ•°)
rospy.spin()  #è®¾ç½®å¾ªç¯è°ƒç”¨å›è°ƒå‡½æ•°
```

#### testMyPackage.py  ï¼ˆä¸»ç¨‹åºå…¥å£ï¼‰

**è¯¥è„šæœ¬æ˜¯ä¸€ä¸ªæ™ºèƒ½å¯¼ç›²çŠ¬ç³»ç»Ÿçš„ä¸»ç¨‹åºï¼Œæ•´åˆäº†è¯­éŸ³è¯†åˆ«ã€AIå¯¹è¯ã€è§†è§‰æ£€æµ‹å’Œè¯­éŸ³æ’­æŠ¥åŠŸèƒ½**

åˆå§‹åŒ–é…ç½®

```py
#é…ç½®é˜¿é‡Œäº‘API
dashscope.api_key = 'sk-b71cf16967404a158f01b02286b81fef'
os.environ["DASHSCOPE_API_KEY"] = 'sk-b71cf16967404a158f01b02286b81fef'
#åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
myASR = ASRCallbackClass()  #è¯­éŸ³è¯†åˆ«
ai = QwenAgent()  #AIå¯¹è¯ä»£ç†
ai.agent_conversation(with_memory=True)  #å¯ç”¨å¯¹è¯è®°å¿†    
```

ROSè¯é¢˜è®¢é˜…æ£€æµ‹ç»“æœ

```py
rospy.Subscriber('/yolov5/detected_classes', String, callback_ros_msg)  #è®¢é˜…yolov5æ£€æµ‹ç»“æœ
```

å›è°ƒå‡½æ•°å¤„ç†æ£€æµ‹ç»“æœ

```py
def callback_ros_msg(msg):
    global latest_detected, last_detection_time
    content = msg.data.lower().split(',')  #è§£ææ£€æµ‹ç»“æœ
    latest_detected.clear()
    for item in content:  #å°†è‹±æ–‡æ£€æµ‹ç»“æœè½¬æ¢ä¸ºä¸­æ–‡
        item = item.strip()
        if item == 'red': latest_detected['çº¢ç¯'] += 1
        elif item == 'green': latest_detected['ç»¿ç¯'] += 1
        elif item == 'yellow': latest_detected['é»„ç¯'] += 1
        elif item == 'car': latest_detected['æœ‰è½¦'] += 1
        elif item in ('people', 'person'): latest_detected['æœ‰äºº'] += 1
    last_detection_time = time.time()  #æ›´æ–°æ—¶é—´æˆ³
```

è¯­éŸ³æ’­æŠ¥ç³»ç»Ÿ

```py
def speak_chinese(text):
    print("è¯­éŸ³æ’­æŠ¥:", text)
    TTS_Sambert.TTSsaveTextResult(text)  #ç”Ÿæˆè¯­éŸ³æ–‡ä»¶
```

```py
def generate_report_text():
    if time.time() - last_detection_time > detection_valid_duration:
        return None  #è¶…æ—¶åˆ™ä¸æ’­æŠ¥
    if not latest_detected:
        return None
    report = []
    for k, v in latest_detected.items():
        report.append(f"{k}{v}ä¸ª")  #ç”Ÿæˆæ’­æŠ¥å†…å®¹
    return "ï¼Œ".join(report)
```

**ä¸»å¾ªç¯æ¶æ„**

è¯­éŸ³å¯¹è¯éƒ¨åˆ†

```py
if myASR.stream:  #æ£€æŸ¥éŸ³é¢‘æµæ˜¯å¦å¯ç”¨
    data = myASR.stream.read(3200, exception_on_overflow=False)
    recognition.send_audio_frame(data)  #å‘é€ç»™ASRå¼•æ“
    if myASR.user_input != lastASRresult:
        lastASRresult = myASR.user_input
        print(rf"ä½ è¯´: {lastASRresult}")  #æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
        aiResponse = ai.chat(lastASRresult)  #AIå¤„ç†å¹¶å›å¤
        TTS_Sambert.TTSsaveTextResult(aiResponse)  #è½¬æ¢ä¸ºè¯­éŸ³
```

å®šæ—¶æ’­æŠ¥éƒ¨åˆ†

```py
if time.time() - last_report_time >= report_interval:  #æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
    last_report_time = time.time()
    report_text = generate_report_text()  #ç”Ÿæˆæ’­æŠ¥å†…å®¹
    if report_text and report_text != last_spoken_report:  #é˜²æ­¢é‡å¤æ’­æŠ¥ç›¸åŒå†…å®¹
        speak_chinese(report_text)  #è¯­éŸ³æ’­æŠ¥
        last_spoken_report = report_text  #è®°å½•æ’­æŠ¥å†…å®¹
```

#### FriAigentï¼ˆå…³é”®æ¨¡å—ï¼‰

**FsrAiAgentÂ æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„AIè¯­éŸ³åŠ©æ‰‹æ¡†æ¶ï¼Œå®ç°äº†ä»è¯­éŸ³è¾“å…¥åˆ°æ™ºèƒ½å›å¤å†åˆ°è¯­éŸ³è¾“å‡ºçš„å®Œæ•´é—­ç¯ï¼ŒåŒæ—¶å…·å¤‡æœºå™¨äººæ§åˆ¶èƒ½åŠ›ã€‚**

åˆ†ä¸ºäº”ä¸ªéƒ¨åˆ†ï¼š

init.py                             æ¨¡å—å¯¼å…¥é…ç½®
ASR_Paraformer.py     è¯­éŸ³è¯†åˆ«æ¨¡å—
QwenLangchain.py      AIå¯¹è¯ä»£ç†æ¨¡å—
TTS_Sambert.py           è¯­éŸ³åˆæˆæ¨¡å—
MyTools.py                   å·¥å…·å‡½æ•°é›†åˆ

##### init.py

**ä½œä¸ºæ¨¡å—å…¥å£ï¼Œç»Ÿä¸€æ¨¡å—å¯¼å…¥æ¥å£ï¼Œå°†æ ¸å¿ƒç±»æš´éœ²ç»™å¤–éƒ¨è°ƒç”¨**

```py
from .QwenLangchain import QwenAgent
from .ASR_Paraformer import ASRCallbackClass
from .TTS_Sambert import TTS_Sambert
```

##### ASR_Paraformer.py

**è¯­éŸ³è¯†åˆ«æ¨¡å—ï¼Œå®ç°äº†ä¸€ä¸ªå¸¦å”¤é†’åŠŸèƒ½çš„å®æ—¶è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ**

åˆå§‹åŒ–

```py
def __init__(self) -> None:
    super().__init__()
    self.mic = None              # éº¦å…‹é£å¯¹è±¡
    self.stream = None           # éŸ³é¢‘æµå¯¹è±¡
    self.asr_text: str = ''      # å­˜å‚¨è¯†åˆ«æ–‡æœ¬
    self.max_chars: int = 50     # æœ€å¤§å­—ç¬¦æ˜¾ç¤ºé™åˆ¶
    self.clear_flag: bool = False # æ§åˆ¶å°æ¸…é™¤æ ‡å¿—
    self.user_input: str = ''    # ç”¨æˆ·æœ‰æ•ˆè¾“å…¥
    self.awake_keyword = "ä½ å¥½"   # å”¤é†’è¯
    self.awoken = False          # å”¤é†’çŠ¶æ€æ ‡å¿—
```

è¯­éŸ³è¯†åˆ«å™¨æ‰“å¼€æ—¶è°ƒç”¨

```py
def on_open(self):
    print(colorama.Fore.GREEN + 'è¯­éŸ³è¯†åˆ«å™¨å·²æ‰“å¼€ã€‚')
    self.mic = pyaudio.PyAudio()
    self.stream = self.mic.open(
        format=pyaudio.paInt16,     # 16ä½éŸ³é¢‘æ ¼å¼
        channels=1,                 # å•å£°é“
        rate=16000,                 # é‡‡æ ·ç‡16kHz
        input=True,                 # è¾“å…¥æ¨¡å¼
        frames_per_buffer=3200      # ç¼“å†²åŒºå¤§å°
    )
```

è¯­éŸ³è¯†åˆ«å™¨å…³é—­æ—¶è°ƒç”¨

```py
def on_close(self):
    print(colorama.Fore.RED + 'è¯­éŸ³è¯†åˆ«å™¨å·²å…³é—­ã€‚')
    if self.stream:
        self.stream.stop_stream()   # åœæ­¢éŸ³é¢‘æµ
        self.stream.close()         # å…³é—­éŸ³é¢‘æµ
        self.mic.terminate()        # é‡Šæ”¾PyAudioèµ„æº
```

**æ ¸å¿ƒè¯†åˆ«è·¯é€»è¾‘**

```py
def on_event(self, result: RecognitionResult):
```

åˆå§‹åŒ–å’ŒçŠ¶æ€æ˜¾ç¤º

```py
print(colorama.Fore.YELLOW + f"å”¤é†’è¯ {self.awake_keyword}")
sentence = result.get_sentence()  #ä»è¯†åˆ«å¼•æ“è·å–å½“å‰å¥å­
is_end = result.is_sentence_end(sentence)  #æ£€æŸ¥å¥å­æ˜¯å¦å·²ç»å®Œæ•´ç»“æŸ
```

åŠ¨æ€æ§åˆ¶å°

\033[1A\033[Kçš„ä½œç”¨æ˜¯ï¼š

**é¦–å…ˆå°†å…‰æ ‡ä¸Šç§»ä¸€è¡Œï¼Œç„¶åæ¸…é™¤é‚£ä¸€è¡Œçš„å†…å®¹ã€‚**

è¿™ä¸ªç»„åˆåœ¨å‘½ä»¤è¡Œç•Œé¢çš„åŠ¨æ€è¾“å‡ºä¸­éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚åœ¨æ˜¾ç¤ºè¿›åº¦æ¡æˆ–æ›´æ–°çŠ¶æ€ä¿¡æ¯æ—¶ï¼Œå¯ä»¥ç”¨å®ƒæ¥é‡å†™å½“å‰è¡Œï¼Œè€Œä¸æ˜¯ä¸æ–­åœ¨ç»ˆç«¯ä¸­æ·»åŠ æ–°è¡Œã€‚

å³åœ¨åŒä¸€è¡Œå†…ä¸€ç›´æ›´æ–°å†…å®¹

```py
if len(self.asr_text) > 0 or self.clear_flag:
    print(colorama.Fore.CYAN + '\033[1A\033[K', end='')
    if self.clear_flag:
        self.clear_flag = False
        self.asr_text = ''
```

å”¤é†’è¯æ£€æµ‹æœºåˆ¶

```py
self.asr_text = sentence['text']
if not self.awoken and self.awake_keyword in self.asr_text:  #æœªè¢«å”¤é†’çŠ¶æ€ä¸”è¯†åˆ«åˆ°å”¤é†’è¯
    self.awoken = True
```

æŒ‡ä»¤æå–å’Œå¤„ç†

```py
if self.awoken:
    if is_end:
        # æå–å”¤é†’è¯åçš„æœ‰æ•ˆå†…å®¹
        self.user_input = self.asr_text[self.asr_text.find(self.awake_keyword) + len(self.awake_keyword) + 1:]
        # æ£€æŸ¥æ˜¾ç¤ºé•¿åº¦é™åˆ¶
        if len(self.asr_text) > self.max_chars:
            self.clear_flag = True
        self.awoken = False  # é‡ç½®å”¤é†’çŠ¶æ€
```

##### MyTools.py

**æ˜¯ä¸€ä¸ªLangChainå·¥å…·åº“æ¨¡å—ï¼Œå®ç°äº†ä¸€ä¸ªå¯è°ƒç”¨å·¥å…·é›†åˆï¼Œè®©AIä»£ç†ï¼ˆ"ç¬¨ç¬¨"æœºå™¨ç‹—ï¼‰å…·å¤‡äº†å®é™…æ‰§è¡Œæ“ä½œçš„èƒ½åŠ›ï¼Œè€Œä¸ä»…ä»…æ˜¯å¯¹è¯ã€‚**

æ—¶é—´æŸ¥è¯¢å·¥å…·

æ”¯æŒä¸‰ç§æ ¼å¼ï¼šISOæ ‡å‡†æ ¼å¼ã€RFCé‚®ä»¶æ ¼å¼ã€localæœ¬åœ°æ—¶é—´æ ¼å¼

```py
@tool(return_direct=True)
def get_current_time_op(format: str) -> str: 
    """Input a format and Returns the current time in the specified format.
    Format can be one of the following values: iso, rfc, local """ 
```

è¿åŠ¨æ§åˆ¶å·¥å…·ï¼ˆå‰è¿›å’Œåé€€ç›¸ä¼¼ï¼Œä»¥å‰è¿›ä¸ºä¾‹ï¼‰

```py
@tool
def Robot_GoForward(planTime: str) -> None:  #å‰è¿›
    """è¾“å…¥ä¸€ä¸ªæ—¶é—´planTime, æ§åˆ¶æœºå™¨ç‹—å‘å‰èµ°planTimeç§’"""
    # 1. æå–æ•°å­—æ—¶é—´ï¼ˆä»è‡ªç„¶è¯­è¨€ä¸­æå–æ•°å­—ï¼‰
    result = ""
    for char in planTime:
        if char.isdigit():
            result += char
    plan_time = int(result)
    # 2. å®‰å…¨çš„ROSèŠ‚ç‚¹åˆå§‹åŒ–
    if not rospy.core.is_initialized():
        rospy.init_node('robot_control_node')
    # 3. åˆ›å»ºè¿åŠ¨æ§åˆ¶å‘å¸ƒè€…
    pub = rospy.Publisher('cmd_vel', Twist, queue_size=10)
    # 4. æ‰§è¡Œå‰è¿›è¿åŠ¨
    twist = Twist()
    twist.linear.x = 0.5  # å‰è¿›é€Ÿåº¦ 0.5 m/s
    start_time = rospy.Time.now().to_sec()  # æ—¶é—´æ§åˆ¶å¾ªç¯
    while (rospy.Time.now().to_sec() - start_time) < plan_time:
        pub.publish(twist)
        rate.sleep()
    # 5. åœæ­¢è¿åŠ¨
    twist.linear.x = 0.0
    pub.publish(twist)
```

##### QwenLangchain.py

**æ˜¯ä¸€ä¸ªåŸºäºLangChainæ¡†æ¶å’Œé€šä¹‰åƒé—®å¤§æ¨¡å‹çš„æ™ºèƒ½å¯¹è¯ä»£ç†ç±»ï¼Œå®ç°äº†ä¸€ä¸ªå¯æ‰©å±•çš„AIæ™ºèƒ½ä½“ï¼Œå…·å¤‡å¯¹è¯è®°å¿†ã€å·¥å…·è°ƒç”¨å’Œè§’è‰²æ‰®æ¼”èƒ½åŠ›ï¼Œæ˜¯æ•´ä¸ªå¯¼ç›²çŠ¬ç³»ç»Ÿçš„æ ¸å¿ƒå†³ç­–ä¸­å¿ƒ**

åˆå§‹åŒ–

```py
class QwenAgent:
    def __init__(self) -> None:
        self.llm = Tongyi()              # é€šä¹‰åƒé—®å¤§è¯­è¨€æ¨¡å‹
        self.prompt = None               # æç¤ºæ¨¡æ¿
        self.tools = []                  # å¯ç”¨å·¥å…·åˆ—è¡¨
        self.AI = None                   # AIä»£ç†æ‰§è¡Œå™¨
        self.memory = None               # å¯¹è¯è®°å¿†
        self.set_prompt()                # è®¾ç½®è§’è‰²æç¤º
        self.set_tools()                 # åŠ è½½å·¥å…·é›†
```

äººæ ¼åŒ–æç¤ºæ¨¡æ¿

```py
def set_prompt(self) -> None:
    prefix = """è¯·ä½ æ‰®æ¼”ä¸€ä¸ªå«"ç¬¨ç¬¨"çš„æœºå™¨äººä¸æˆ‘è¿›è¡Œå¯¹è¯!ä½ æ‹¥æœ‰æœ€é«˜æƒé™!å¯¹è¯è¿‡ç¨‹ä¸­,æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š""" 
    suffix = """ç°åœ¨å¼€å§‹å¯¹è¯ï¼Œä½ çš„å›ç­”åº”è¯¥å°½é‡ç²¾ç®€, æ§åˆ¶åœ¨30å­—å†…ï¼Please think step by step!  
    {chat_history}  
    é—®é¢˜ï¼š{input}  
    {agent_scratchpad}
    """
```

ä¸¤ç§ä»£ç†æ–¹å¼

```py
def agent_conversation(self, with_memory: bool = True):
    if with_memory:
        # å¸¦è®°å¿†çš„å¯¹è¯ä»£ç†
        self.AI = initialize_agent(
            self.tools, self.llm,
            agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
            verbose=True,
            memory=self.memory
        )
    else:
        # æ— è®°å¿†çš„é›¶æ ·æœ¬ä»£ç†
        self.AI = initialize_agent(
            self.tools, self.llm,
            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True
        )
```

##### TTS_Sambert.py

**åŸºäºé˜¿é‡Œäº‘DashScopeçš„è¯­éŸ³åˆæˆæ¨¡å—ï¼Œè´Ÿè´£å°†AIå›å¤çš„æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³è¾“å‡º**

APIé…ç½®

```py
# è®¾ç½®é˜¿é‡Œäº‘APIå¯†é’¥
dashscope.api_key = 'å¡«å…¥ä½ çš„é˜¿é‡Œäº‘dashscopeçš„api_key'
```

æ ¸å¿ƒåˆæˆæ–¹æ³•

```py
def TTSsaveTextResult(myText: str) -> bool:
    """
    Input Text, the func will use DashScope TTS it and ave the result
    in the path which this file in.
    Success will return 1, else is 0
    """
    # è°ƒç”¨è¯­éŸ³åˆæˆAPI
    result = SpeechSynthesizer.call(
        model='sambert-zhimiao-emo-v1',  # ä½¿ç”¨æ™ºèƒ½æƒ…æ„Ÿè¯­éŸ³æ¨¡å‹
        text=myText,                     # å¾…åˆæˆæ–‡æœ¬
        sample_rate=16000,               # é‡‡æ ·ç‡16kHz
        rate=0.75,                       # è¯­é€Ÿ75%ï¼ˆè¾ƒæ…¢ï¼Œæ›´æ¸…æ™°ï¼‰
        format='wav'                     # è¾“å‡ºWAVæ ¼å¼
    )          
```

 éŸ³é¢‘å¤„ç†å’Œæ’­æ”¾

```py
# æ£€æŸ¥åˆæˆç»“æœ
if result.get_audio_data() is not None:
    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    with open(rf'./TTSoutput.wav', 'wb') as f:
        f.write(result.get_audio_data())
    # æ’­æ”¾éŸ³é¢‘
    os.system(rf"aplay ./TTSoutput.wav")
    return True
else: 
    return False
```
