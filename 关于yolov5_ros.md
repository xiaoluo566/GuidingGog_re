# å…³äºyolov5_ros

## å®ç°ç›®çš„

å®ç°äº†ä¸€ä¸ªåŸºäºYOLOv5çš„ROSè§†è§‰æ£€æµ‹ç³»ç»Ÿï¼Œä¸ºå¯¼ç›²çŠ¬æä¾›å®æ—¶çš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›

## rosåŒ…æ¡†æ¶

ğŸ“¦  /
â”œâ”€â”€ ğŸ“„ README.md                    # è‹±æ–‡è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ ğŸ“„ README_CN.md                 # ä¸­æ–‡è¯´æ˜æ–‡æ¡£
â””â”€â”€ ğŸ“ yolov5_ros                  # ä¸»è¦åŠŸèƒ½åŒ…ç›®å½•
    â”œâ”€â”€ ğŸ“ yolov5_ros              # æ ¸å¿ƒæ£€æµ‹åŠŸèƒ½åŒ…
    â”‚   â”œâ”€â”€ ğŸ“„ CMakeLists.txt       # ROSåŒ…æ„å»ºé…ç½®
    â”‚   â”œâ”€â”€ ğŸ“„ package.xml          # ROSåŒ…ä¾èµ–å£°æ˜
    â”‚   â”œâ”€â”€ ğŸ“„ package.xml.bak      # é…ç½®æ–‡ä»¶å¤‡ä»½
    â”‚   â”œâ”€â”€ ğŸ“ launch              # ROSå¯åŠ¨æ–‡ä»¶
    â”‚   â”‚   â””â”€â”€ ğŸ“„ yolo_v5.launch   # ä¸»å¯åŠ¨é…ç½®
    â”‚   â”œâ”€â”€ ğŸ“ scripts             # Pythonæ‰§è¡Œè„šæœ¬
    â”‚   â”‚   â””â”€â”€ ğŸ“„ yolo_v5.py       # æ ¸å¿ƒæ£€æµ‹è„šæœ¬
    â”‚   â”œâ”€â”€ ğŸ“ weights             # æ¨¡å‹æƒé‡æ–‡ä»¶
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ download_weights.sh  # æƒé‡ä¸‹è½½è„šæœ¬
    â”‚   â”‚   â””â”€â”€ ğŸ“„ yolov5s.pt       # YOLOv5sé¢„è®­ç»ƒæƒé‡
    â”‚   â”œâ”€â”€ ğŸ“ media               # åª’ä½“èµ„æº
    â”‚   â”‚   â””â”€â”€ ğŸ“„ image.png        # æ¼”ç¤ºå›¾ç‰‡
    â”‚   â””â”€â”€ ğŸ“ yolov5              # YOLOv5æºç ç›®å½•ï¼ˆä»…åˆ—å‡ºä¸»è¦æ–‡ä»¶ï¼‰
    â”‚       â”œâ”€â”€ ğŸ“„ detect.py        # æ£€æµ‹è„šæœ¬
    â”‚       â”œâ”€â”€ ğŸ“„ export.py        # æ¨¡å‹å¯¼å‡º
    â”‚       â”œâ”€â”€ ğŸ“„ requirements.txt # Pythonä¾èµ–
    â”‚       â”œâ”€â”€ ğŸ“„ Dockerfile       # Dockeré…ç½®
    â”‚       â”œâ”€â”€ ğŸ“„ LICENSE          # å¼€æºè®¸å¯è¯
    â”‚       â””â”€â”€ ğŸ“ utils           # å·¥å…·å‡½æ•°åº“
    â””â”€â”€ ğŸ“ yolov5_ros_msgs         # ROSæ¶ˆæ¯å®šä¹‰åŒ…
        â”œâ”€â”€ ğŸ“„ CMakeLists.txt       # æ¶ˆæ¯åŒ…æ„å»ºé…ç½®
        â”œâ”€â”€ ğŸ“„ package.xml          # æ¶ˆæ¯åŒ…ä¾èµ–å£°æ˜
        â””â”€â”€ ğŸ“ msg                 # æ¶ˆæ¯ç±»å‹å®šä¹‰
            â”œâ”€â”€ ğŸ“„ BoundingBox.msg     # å•ä¸ªæ£€æµ‹æ¡†æ¶ˆæ¯
            â””â”€â”€ ğŸ“„ BoundingBoxes.msg # å¤šä¸ªæ£€æµ‹æ¡†æ¶ˆæ¯

## ä»£ç è§£é‡Š

### yolov5_ros_msgsï¼ˆROSæ¶ˆæ¯å®šä¹‰åŒ…ï¼‰

æ˜¯ä¸€ä¸ªROSæ¶ˆæ¯å®šä¹‰åŒ…ï¼Œä¸“é—¨ç”¨äºå®šä¹‰å’Œç®¡ç†ç›®æ ‡æ£€æµ‹ç›¸å…³çš„è‡ªå®šä¹‰æ¶ˆæ¯ç±»å‹

å…¶ä¸­msgæ–‡ä»¶å¤¹ä¸‹å­˜æ”¾ä¸¤ä¸ªmsgæ–‡ä»¶ï¼šBoundingBox.msgã€BoundingBoxes.msg

#### BoundingBox.msg

æè¿°ç›®æ ‡æ£€æµ‹ç®—æ³•æ£€æµ‹åˆ°çš„**å•ä¸ªç‰©ä½“çš„è¾¹ç•Œæ¡†ä¿¡æ¯**

æ¯æ£€æµ‹åˆ°ä¸€ä¸ªç›®æ ‡ï¼Œå°±ä¼šç”Ÿæˆä¸€ä¸ªÂ BoundingBox æ¶ˆæ¯ï¼Œå¤šä¸ªç›®æ ‡ä¼šç»„æˆÂ BoundingBoxes æ¶ˆæ¯è¿›è¡Œå‘å¸ƒ

```
float64 probability   # ç½®ä¿¡åº¦ï¼Œè¡¨ç¤ºæ£€æµ‹ç»“æœçš„å¯ä¿¡ç¨‹åº¦ï¼ˆ0~1ä¹‹é—´çš„å°æ•°ï¼‰
int64 xmin            # è¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„xåæ ‡
int64 ymin            # è¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„yåæ ‡
int64 xmax            # è¾¹ç•Œæ¡†å³ä¸‹è§’çš„xåæ ‡
int64 ymax            # è¾¹ç•Œæ¡†å³ä¸‹è§’çš„yåæ ‡
int16 num             # ç›®æ ‡ç±»åˆ«ç¼–å·
string Class          # ç›®æ ‡ç±»åˆ«åç§°
```

#### BoundingBoxes.msg

æè¿°ä¸€å¸§å›¾åƒä¸­**æ‰€æœ‰æ£€æµ‹åˆ°çš„ç›®æ ‡**çš„é›†åˆä¿¡æ¯

```
Header header              # ROSæ ‡å‡†æ¶ˆæ¯å¤´ï¼ŒåŒ…å«æ—¶é—´æˆ³ã€åºåˆ—å·ã€åæ ‡ç³»ç­‰å…ƒä¿¡æ¯
Header image_header        # åŸå§‹å›¾åƒçš„æ¶ˆæ¯å¤´ï¼Œè®°å½•å›¾åƒé‡‡é›†æ—¶çš„æ—¶é—´æˆ³å’Œåæ ‡ç³»
BoundingBox[] bounding_boxes  # è¾¹ç•Œæ¡†æ•°ç»„ï¼ŒåŒ…å«è¯¥å¸§å›¾åƒä¸­æ‰€æœ‰æ£€æµ‹åˆ°çš„ç›®æ ‡
```

### yolov5_rosï¼ˆä¸»è¦åŠŸèƒ½åŒ…ï¼‰

#### scripts/yolo_v5.py

##### Yolo_Dectç±»

###### __init__

```py
def __init__(self):
```

å…ˆä»ROSå‚æ•°æœåŠ¡å™¨è·å–é…ç½®

```python
yolov5_path = rospy.get_param('/yolov5_path', '')           # YOLOv5ä»£ç è·¯å¾„
weight_path = rospy.get_param('~weight_path', '')           # æƒé‡æ–‡ä»¶è·¯å¾„
image_topic = rospy.get_param('~image_topic', '/camera/color/image_raw')  # è¾“å…¥å›¾åƒè¯é¢˜
pub_topic = rospy.get_param('~pub_topic', '/yolov5/BoundingBoxes')       # è¾“å‡ºè¯é¢˜
conf = rospy.get_param('~conf', '0.5')                     # ç½®ä¿¡åº¦é˜ˆå€¼
```

åŠ è½½æœ¬åœ°yolovæ¨¡å‹

```py
self.model = torch.hub.load(yolov5_path, 'custom',path=weight_path, source='local')
```

ROSé€šä¿¡è®¾ç½®

ä¸‰ç§ç±»å‹å‘å¸ƒè€…

```py
# è®¢é˜…å›¾åƒè¯é¢˜
self.color_sub = rospy.Subscriber(image_topic, Image, self.image_callback,queue_size=1, buff_size=52428800)  # å¤§ç¼“å†²åŒºé˜²æ­¢å›¾åƒä¸¢å¤±
# å‚æ•° queue_size=1 ä¸º æ¶ˆæ¯é˜Ÿåˆ—=1
# åˆ›å»ºå‘å¸ƒè€…
self.position_pub = rospy.Publisher('/yolov5/BoundingBoxes', BoundingBoxes, queue_size=1)
self.image_pub = rospy.Publisher('/yolov5/detection_image', Image, queue_size=1)
self.class_pub = rospy.Publisher('/yolov5/detected_classes', String, queue_size=1)
```

###### image_callbackï¼ˆå›¾åƒå›è°ƒå¤„ç†å‡½æ•°ï¼‰

```py
def image_callback(self, image):
```

```py
# åˆ›å»ºæ£€æµ‹ç»“æœæ¶ˆæ¯å®¹å™¨
self.boundingBoxes = BoundingBoxes() # åˆ›å»ºæ¶ˆæ¯å®¹å™¨
self.boundingBoxes.header = image.header # è®¾ç½®æ¶ˆæ¯å¤´
self.boundingBoxes.image_header = image.header # ä¿å­˜å›¾åƒå¤´ä¿¡æ¯
# å›¾åƒæ•°æ®è½¬æ¢
self.color_image = np.frombuffer(image.data, dtype=np.uint8).reshape(image.height, image.width, -1)
self.color_image = cv2.cvtColor(self.color_image, cv2.COLOR_BGR2RGB)
# YOLOv5æ¨ç†æ£€æµ‹
results = self.model(self.color_image)
boxs = results.pandas().xyxy[0].values  # è·å–æ£€æµ‹æ¡†æ•°æ®
# å¤„ç†æ£€æµ‹ç»“æœï¼ˆä½¿ç”¨dectshowå‡½æ•°ï¼‰
self.dectshow(self.color_image, boxs, image.height, image.width)
```

###### dectshowï¼ˆæ£€æµ‹ç»“æœå¤„ç†å‡½æ•°ï¼‰

```py
def dectshow(self, org_img, boxs, height, width):
```

**æ£€æµ‹æ¡†å¤„ç†å¾ªç¯**

```py
img = org_img.copy()
detected_classes = []  # å­˜å‚¨æ‰€æœ‰æ£€æµ‹åˆ°çš„ç±»åˆ«    
# ç»Ÿè®¡æ£€æµ‹ç›®æ ‡æ•°é‡
count = len(boxs)  
for box in boxs:
    # åˆ›å»ºBoundingBoxæ¶ˆæ¯
    boundingBox = BoundingBox()
    boundingBox.probability = np.float64(box[4])  # ç½®ä¿¡åº¦
    boundingBox.xmin = np.int64(box[0])           # å·¦ä¸Šè§’x
    boundingBox.ymin = np.int64(box[1])           # å·¦ä¸Šè§’y
    boundingBox.xmax = np.int64(box[2])           # å³ä¸‹è§’x
    boundingBox.ymax = np.int64(box[3])           # å³ä¸‹è§’y
    boundingBox.num = np.int16(count)             # æ€»æ£€æµ‹æ•°
    boundingBox.Class = box[-1]                   # ç±»åˆ«åç§°   
    detected_classes.append(box[-1])              # æ”¶é›†ç±»åˆ«ä¿¡æ¯
```

**å¯¹æ£€æµ‹ç»“æœè¿›è¡Œç»˜åˆ¶**

ä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…é¢œè‰²

```py
if box[-1] in self.classes_colors.keys():     # æ£€æŸ¥ç±»åˆ«æ˜¯å¦å·²æœ‰é¢œè‰²
    color = self.classes_colors[box[-1]]      # å·²æœ‰åˆ™ç›´æ¥ä½¿ç”¨è¯¥é¢œè‰²
else:
    color = np.random.randint(0, 183, 3)      # éšæœºç”Ÿæˆé¢œè‰²
    self.classes_colors[box[-1]] = color
```

ç»˜åˆ¶æ£€æµ‹æ¡†

```py
cv2.rectangle(img, (int(box[0]), int(box[1])),(int(box[2]), int(box[3])), (int(color[0]), int(color[1]), int(color[2])), 2)
```

æ™ºèƒ½æ ‡ç­¾ä½ç½®è®¡ç®—

```py
if box[1] < 20:  # box[1]ä¸ºå·¦ä¸Šè§’y
    text_pos_y = box[1] + 30  # å¦‚æœå¤ªé è¿‘é¡¶éƒ¨ï¼Œæ ‡ç­¾æ”¾åœ¨ä¸‹æ–¹
else:
    text_pos_y = box[1] - 10  # æ­£å¸¸æƒ…å†µæ ‡ç­¾æ”¾åœ¨ä¸Šæ–¹
```

ç»˜åˆ¶ç±»åˆ«æ ‡ç­¾

```py
cv2.putText(img, box[-1],(int(box[0]), int(text_pos_y)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)
```

æ¶ˆæ¯å‘å¸ƒ

```py
# æ·»åŠ åˆ°æ£€æµ‹ç»“æœé›†åˆ
self.boundingBoxes.bounding_boxes.append(boundingBox)    
# å‘å¸ƒBoundingBoxesæ¶ˆæ¯
self.position_pub.publish(self.boundingBoxes)    
# å‘å¸ƒæ£€æµ‹ç±»åˆ«åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰
if detected_classes:
    class_msg = String()
    class_msg.data = ", ".join(detected_classes) 
    self.class_pub.publish(class_msg) 
# å‘å¸ƒå¯è§†åŒ–å›¾åƒå’Œæ˜¾ç¤º
self.publish_image(img, height, width)
cv2.imshow('YOLOv5', img)
```

###### publish_imageï¼ˆå›¾åƒå‘å¸ƒå‡½æ•°ï¼‰

```py
def publish_image(self, imgdata, height, width):
```

```py
image_temp = Image()  # åˆ›å»ºå›¾åƒæ¶ˆæ¯å¯¹è±¡
header = Header(stamp=rospy.Time.now())  #åˆ›å»ºæ¶ˆæ¯å¤´å¹¶è®¾ç½®æ—¶é—´æˆ³ï¼ˆrospy.Time.now()å¯è·å–å½“å‰rosç³»ç»Ÿæ—¶é—´ï¼‰
header.frame_id = self.camera_frame  # è®¾ç½®åæ ‡ç³»ID
```

è®¾ç½®å›¾åƒå±æ€§

```py
image_temp.height = height
image_temp.width = width
image_temp.encoding = 'bgr8'                    # å›¾åƒç¼–ç æ ¼å¼
image_temp.data = np.array(imgdata).tobytes()   # å›¾åƒæ•°æ®è½¬å­—èŠ‚
image_temp.header = header
image_temp.step = width * 3                     # æ¯è¡Œå­—èŠ‚æ•°
```

##### mainï¼ˆä¸»å‡½æ•°ï¼‰

```py
def main():
    rospy.init_node('yolov5_ros', anonymous=True)  # åˆå§‹åŒ–ROSèŠ‚ç‚¹
    yolo_dect = Yolo_Dect()                        # åˆ›å»ºæ£€æµ‹å¯¹è±¡
    rospy.spin()                                   # è¿›å…¥ROSå¾ªç¯
```

#### yolov5/detect.py

è¯¥è„šæœ¬è´Ÿè´£æä¾›å¯é çš„ç›®æ ‡æ£€æµ‹èƒ½åŠ›

ç”¨äºå¯¹å›¾åƒã€è§†é¢‘ã€æ‘„åƒå¤´ç­‰å¤šç§è¾“å…¥æºè¿›è¡Œç›®æ ‡æ£€æµ‹

##### runå‡½æ•°

```py
def run(weights=ROOT / 'yolov5s.pt',  # model.pt path(s)
        source=ROOT / 'data/images',  # file/dir/URL/glob, 0 for webcam
        data=ROOT / 'data/coco128.yaml',  # dataset.yaml path
        imgsz=(640, 640),  # inference size (height, width)
        conf_thres=0.25,  # confidence threshold
        iou_thres=0.45,  # NMS IOU threshold
        max_det=1000,  # maximum detections per image
        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu
        view_img=False,  # show results
        save_txt=False,  # save results to *.txt
        save_conf=False,  # save confidences in --save-txt labels
        save_crop=False,  # save cropped prediction boxes
        nosave=False,  # do not save images/videos
        classes=None,  # filter by class: --class 0, or --class 0 2 3
        agnostic_nms=False,  # class-agnostic NMS
        augment=False,  # augmented inference
        visualize=False,  # visualize features
        update=False,  # update all models
        project=ROOT / 'runs/detect',  # save results to project/name
        name='exp',  # save results to project/name
        exist_ok=False,  # existing project/name ok, do not increment
        line_thickness=3,  # bounding box thickness (pixels)
        hide_labels=False,  # hide labels
        hide_conf=False,  # hide confidences
        half=False,  # use FP16 half-precision inference
        dnn=False,  # use OpenCV DNN for ONNX inference
        ):
```

è¾“å…¥æºåˆ¤æ–­

```py
source = str(source)  # è½¬ä¸ºå­—ç¬¦ä¸²
save_img = not nosave and not source.endswith('.txt')  # æ˜¯å¦ä¿å­˜æ¨ç†ç»“æœçš„å›¾åƒçš„æ¡ä»¶
is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)  # Path(source).suffix[1:]ä¸ºè·å–æ–‡ä»¶æ‰©å±•å
is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))
webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)  # åˆ¤æ–­ source æ˜¯å¦æ˜¯ä¸€ä¸ªå®æ—¶æµï¼ˆå¦‚æ‘„åƒå¤´ï¼‰æˆ–å…¶ä»–æµåª’ä½“æºï¼ˆsourceä¸ºçº¯æ•°å­—ã€ä¸ºtxtæ–‡ä»¶ã€æ˜¯URLä¸”ä¸æ˜¯æ–‡ä»¶ï¼‰
```

åˆ›å»ºä¿å­˜ç›®å½•

```py
save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment_pathå¯ä»¥å®ç°åœ¨ç›®æ ‡è·¯å¾„å·²å­˜åœ¨æ—¶è‡ªåŠ¨é€’å¢ç›®å½•åç§°
(save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir
```

æ•°æ®åŠ è½½

```py
if webcam:  # åˆ¤æ–­è¾“å…¥æºæ˜¯å¦ä¸ºç½‘ç»œæ‘„åƒå¤´æˆ–æµåª’ä½“
    view_img = check_imshow()  # è°ƒç”¨ check_imshow() æ£€æŸ¥å½“å‰ç³»ç»Ÿæ˜¯å¦æ”¯æŒ cv2.imshow()ï¼ˆæ˜¾ç¤ºå›¾åƒçš„åŠŸèƒ½ï¼‰
    cudnn.benchmark = True  # set True to speed up constant image size inference
    dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)  # æ•°æ®åŠ è½½ï¼Œå¹¶ä¸”å‚æ•°è°ƒèŠ‚å¤§å°
    bs = len(dataset)  # batch_size
else:
    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)
    bs = 1  # batch_size
vid_path, vid_writer = [None] * bs, [None] * bs  # åˆå§‹åŒ–ä¸¤ä¸ªåˆ—è¡¨ï¼Œç”¨äºä¿å­˜è§†é¢‘è·¯å¾„å’Œè§†é¢‘å†™å…¥å™¨
```

é¢„çƒ­+æ•°æ®é¢„å¤„ç†+æ¨ç†

```py
model.warmup(imgsz=(1, 3, *imgsz), half=half)  # é¢„çƒ­
for path, im, im0s, vid_cap, s in dataset:
    t1 = time_sync()  # è®°å½•å½“å‰æ—¶é—´
    im = torch.from_numpy(im).to(device)
    im = im.half() if half else im.float()  # uint8 to fp16/32
    im /= 255  # 0 - 255 to 0.0 - 1.0
    if len(im.shape) == 3:
        im = im[None]  # expand for batch dim
    t2 = time_sync()
    dt[0] += t2 - t1  # æ•°æ®é¢„å¤„ç†
    visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False
    pred = model(im, augment=augment, visualize=visualize)  # å°†é¢„å¤„ç†åçš„å›¾åƒimè¾“å…¥æ¨¡å‹ï¼Œå¾—åˆ°é¢„æµ‹ç»“æœpredï¼ˆæ˜¯å¦ç”¨å¢å¼ºæ¨ç†ã€æ˜¯å¦ä¿å­˜å¯è§†åŒ–ï¼‰
    t3 = time_sync()
    dt[1] += t3 - t2  # è®¡ç®—æ¨ç†æ—¶é—´
```

éæå¤§å€¼æŠ‘åˆ¶

ï¼ˆå¯¹æ¨¡å‹çš„åŸå§‹é¢„æµ‹ç»“æœè¿›è¡Œåå¤„ç†ï¼Œç§»é™¤é‡å çš„è¾¹ç•Œæ¡†ï¼Œä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„æ¡†ï¼‰

```py
    pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)  
    dt[2] += time_sync() - t3  # è®°å½•å¤„ç†æ—¶é—´
```

ç»“æœå¤„ç†

```py
# éå†é¢„æµ‹ç»“æœ
for i, det in enumerate(pred):  # per image
    seen += 1
# å¤„ç†ä¸¤ç§è¾“å…¥æ–¹å¼æ¥é€‰æ‹©è·¯å¾„ï¼ˆæ‘„åƒå¤´æˆ–è€…æ™®é€šè¾“å…¥ï¼‰
    if webcam:  # batch_size >= 1
        p, im0, frame = path[i], im0s[i].copy(), dataset.count
        s += f'{i}: '
    else:
        p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)
# è®¾ç½®ä¿å­˜è·¯å¾„
    p = Path(p)  # to Path
    save_path = str(save_dir / p.name)  # im.jpg
    txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt
# è®°å½•å›¾åƒå°ºå¯¸ä¿¡æ¯
    s += '%gx%g ' % im.shape[2:]  # im.shape[2:]ï¼šè·å–å›¾åƒçš„å®½åº¦å’Œé«˜åº¦
    gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # gnä¸ºå½’ä¸€åŒ–å› å­ï¼Œç”¨äºå°†æ£€æµ‹æ¡†çš„åæ ‡ä»æ¨¡å‹è¾“å…¥å°ºå¯¸æ˜ å°„å›åŸå§‹å›¾åƒå°ºå¯¸
    imc = im0.copy() if save_crop else im0  # for save_crop
# åˆå§‹åŒ–ç»˜å›¾å·¥å…·
    annotator = Annotator(im0, line_width=line_thickness, example=str(names))
# æ£€æµ‹ç»“æœå¤„ç†
    if len(det):
         # Rescale boxes from img_size to im0 size
         det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()
         # scale_coordsï¼šå°†æ£€æµ‹æ¡†çš„åæ ‡ä»æ¨¡å‹è¾“å…¥å°ºå¯¸æ˜ å°„å›åŸå§‹å›¾åƒå°ºå¯¸
# æ‰“å°æ£€æµ‹ç»“æœ
         for c in det[:, -1].unique():
             n = (det[:, -1] == c).sum()  # detections per class
             s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string
         # Write results
# ä¿å­˜æ£€æµ‹ç»“æœ
         for *xyxy, conf, cls in reversed(det):  # xyxyï¼šæ£€æµ‹æ¡†çš„åæ ‡ [x1, y1, x2, y2] confï¼šç½®ä¿¡åº¦ clsï¼šç±»åˆ«ç´¢å¼•
             if save_txt:  # Write to file
                 xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                 line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format
                 with open(txt_path + '.txt', 'a') as f:
                     f.write(('%g ' * len(line)).rstrip() % line + '\n')
# ç»˜åˆ¶æ£€æµ‹æ¡†
             if save_img or save_crop or view_img:  # Add bbox to image
                 c = int(cls)  # integer class
                 label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')
                 annotator.box_label(xyxy, label, color=colors(c, True))  # box_labelï¼šåœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹æ¡†å’Œæ ‡ç­¾
                 if save_crop:
                      save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)
```

##### mainå‡½æ•°

```py
def main(opt):
    check_requirements(exclude=('tensorboard', 'thop'))  # æ£€æŸ¥ä¾èµ–é¡¹
    run(**vars(opt))  # è°ƒç”¨runå‡½æ•°è¿›è¡Œæ¨ç†
```
